#!/usr/bin/env python3
"""
–ó–∞–≥—Ä—É–∑–∫–∞ –∫—É—Ä—Å–æ–≤ –≤–∞–ª—é—Ç –¶–ë –†–§ –∏ —ç–∫—Å–ø–æ—Ä—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç.

–°–∫–∞—á–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å https://cbr.ru/scripts/XML_daily.asp –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Ö –≤ data/export/cbr_of_rub.json

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    # –†—É—á–Ω–æ–π —Ä–µ–∂–∏–º - —É–∫–∞–∑–∞—Ç—å –ø–µ—Ä–∏–æ–¥:
    python scripts/export_cbr_rub.py --start-date 2021-07-01 --end-date 2026-01-29
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º - —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å kolmo_history.json:
    python scripts/export_cbr_rub.py --sync
    
    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–æ —Å–µ–≥–æ–¥–Ω—è:
    python scripts/export_cbr_rub.py --update
"""

import argparse
import json
import logging
import time
import xml.etree.ElementTree as ET
from datetime import date, datetime, timedelta
from pathlib import Path

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
DATA_EXPORT_DIR = Path(__file__).parent.parent / "data" / "export"
CBR_JSON_FILE = DATA_EXPORT_DIR / "cbr_of_rub.json"
KOLMO_HISTORY_FILE = DATA_EXPORT_DIR / "kolmo_history.json"

# URL –¶–ë –†–§
CBR_URL = "https://cbr.ru/scripts/XML_daily.asp"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ retry
MAX_RETRIES = 5
RETRY_BACKOFF_FACTOR = 1.0  # 1s, 2s, 4s, 8s, 16s


def create_session_with_retries() -> requests.Session:
    """–°–æ–∑–¥–∞—ë—Ç —Å–µ—Å—Å–∏—é —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –ø–æ–≤—Ç–æ—Ä–∞–º–∏ –ø—Ä–∏ —Å–µ—Ç–µ–≤—ã—Ö –æ—à–∏–±–∫–∞—Ö."""
    session = requests.Session()
    
    retry_strategy = Retry(
        total=MAX_RETRIES,
        backoff_factor=RETRY_BACKOFF_FACTOR,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET"],
        raise_on_status=False
    )
    
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    session.mount("http://", adapter)
    
    return session


def fetch_cbr_daily(target_date: date, session: requests.Session | None = None) -> dict | None:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫—É—Ä—Å—ã –≤–∞–ª—é—Ç —Å –¶–ë –†–§ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∞—Ç—É.
    
    Args:
        target_date: –î–∞—Ç–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∫—É—Ä—Å–æ–≤
        session: HTTP —Å–µ—Å—Å–∏—è —Å retry (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –∫—É—Ä—Å–∞–º–∏ –≤–∞–ª—é—Ç –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    date_param = target_date.strftime("%d/%m/%Y")
    url = f"{CBR_URL}?date_req={date_param}"
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é —Å–µ—Å—Å–∏—é –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é —Å retry
    http_client = session or create_session_with_retries()
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–∏ ConnectionResetError
    max_connection_retries = 3
    
    for attempt in range(max_connection_retries):
        try:
            response = http_client.get(url, timeout=60)
            response.raise_for_status()
            
            # –ü–∞—Ä—Å–∏–º XML
            root = ET.fromstring(response.content)
            
            # –°–æ–∑–¥–∞—ë–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –¥–∞–Ω–Ω–æ–π –¥–∞—Ç—ã
            daily_data = {
                "date": target_date.strftime("%Y-%m-%d")
            }
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –≤–∞–ª—é—Ç—ã
            valutes = root.findall('Valute')
            
            if not valutes:
                logger.warning(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ {date_param} (–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã—Ö–æ–¥–Ω–æ–π)")
                return None
            
            for valute in valutes:
                char_code = valute.find('CharCode').text
                value_raw = valute.find('Value').text
                
                # –¶–ë –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å–ª–∞ —Å –∑–∞–ø—è—Ç–æ–π, –º–µ–Ω—è–µ–º –Ω–∞ —Ç–æ—á–∫—É
                value_cleaned = value_raw.replace(',', '.')
                
                daily_data[char_code] = value_cleaned
            
            return daily_data
            
        except (ConnectionResetError, requests.exceptions.ConnectionError) as e:
            if attempt < max_connection_retries - 1:
                wait_time = (attempt + 1) * 2
                logger.warning(f"–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–∞–∑–æ—Ä–≤–∞–Ω–æ –∑–∞ {date_param}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_connection_retries}. –ñ–¥—ë–º {wait_time}—Å...")
                time.sleep(wait_time)
            else:
                logger.error(f"–°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ –∑–∞ {date_param} –ø–æ—Å–ª–µ {max_connection_retries} –ø–æ–ø—ã—Ç–æ–∫: {e}")
                return None
        except requests.exceptions.RequestException as e:
            logger.error(f"–°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ –∑–∞ {date_param}: {e}")
            return None
        except ET.ParseError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ XML –∑–∞ {date_param}: {e}")
            return None
    
    return None


def fetch_cbr_period(start_date: date, end_date: date) -> list[dict]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫—É—Ä—Å—ã –≤–∞–ª—é—Ç –¶–ë –†–§ –∑–∞ –ø–µ—Ä–∏–æ–¥.
    
    Args:
        start_date: –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞
        end_date: –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞
        
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∫—É—Ä—Å–∞–º–∏ –≤–∞–ª—é—Ç
    """
    results = []
    failed_dates = []
    delta = end_date - start_date
    total_days = delta.days + 1
    
    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–µ—Ä–∏–æ–¥: {start_date} ‚Äî {end_date} ({total_days} –¥–Ω–µ–π)")
    
    # –°–æ–∑–¥–∞—ë–º —Å–µ—Å—Å–∏—é —Å retry –¥–ª—è –≤—Å–µ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
    session = create_session_with_retries()
    
    for i in range(total_days):
        current_date = start_date + timedelta(days=i)
        
        daily_data = fetch_cbr_daily(current_date, session)
        
        if daily_data:
            results.append(daily_data)
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {current_date.strftime('%Y-%m-%d')}")
        else:
            failed_dates.append(current_date)
        
        # –ü–∞—É–∑–∞ –¥–ª—è –≤–µ–∂–ª–∏–≤–æ—Å—Ç–∏ –∫ —Å–µ—Ä–≤–µ—Ä—É
        if i < total_days - 1:
            time.sleep(0.2)
    
    # –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –¥–ª—è –Ω–µ—É–¥–∞—á–Ω—ã—Ö –¥–∞—Ç
    if failed_dates:
        logger.info(f"–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –¥–ª—è {len(failed_dates)} –¥–∞—Ç...")
        time.sleep(2)
        
        for failed_date in failed_dates[:]:
            daily_data = fetch_cbr_daily(failed_date, session)
            if daily_data:
                results.append(daily_data)
                failed_dates.remove(failed_date)
                logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–µ: {failed_date.strftime('%Y-%m-%d')}")
            time.sleep(0.5)
    
    if failed_dates:
        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {len(failed_dates)} –¥–∞—Ç: {[d.strftime('%Y-%m-%d') for d in failed_dates]}")
    
    return results


def load_existing_cbr_data() -> list[dict]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ CBR –∏–∑ JSON —Ñ–∞–π–ª–∞."""
    if CBR_JSON_FILE.exists():
        try:
            with open(CBR_JSON_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π –∏–∑ {CBR_JSON_FILE.name}")
                return data
        except (json.JSONDecodeError, IOError) as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {CBR_JSON_FILE}: {e}")
    return []


def load_kolmo_history_dates() -> set[str]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞—Ç—ã –∏–∑ kolmo_history.json."""
    if KOLMO_HISTORY_FILE.exists():
        try:
            with open(KOLMO_HISTORY_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                dates = {record["date"] for record in data if "date" in record}
                logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(dates)} –¥–∞—Ç –≤ {KOLMO_HISTORY_FILE.name}")
                return dates
        except (json.JSONDecodeError, IOError) as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {KOLMO_HISTORY_FILE}: {e}")
    return set()


def save_cbr_data(data: list[dict]):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ CBR –≤ JSON —Ñ–∞–π–ª.
    
    Args:
        data: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∫—É—Ä—Å–∞–º–∏ –≤–∞–ª—é—Ç
    """
    # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    DATA_EXPORT_DIR.mkdir(parents=True, exist_ok=True)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
    data_sorted = sorted(data, key=lambda x: x["date"])
    
    with open(CBR_JSON_FILE, "w", encoding="utf-8") as f:
        json.dump(data_sorted, f, ensure_ascii=False, indent=2)
    
    logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(data_sorted)} –∑–∞–ø–∏—Å–µ–π –≤ {CBR_JSON_FILE}")


def merge_cbr_data(existing: list[dict], new_data: list[dict]) -> list[dict]:
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ CBR.
    –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—é—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–ª—è —Ç–æ–π –∂–µ –¥–∞—Ç—ã.
    
    Args:
        existing: –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        new_data: –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        
    Returns:
        –û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
    """
    # –°–æ–∑–¥–∞—ë–º —Å–ª–æ–≤–∞—Ä—å –ø–æ –¥–∞—Ç–∞–º –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    data_by_date = {record["date"]: record for record in existing}
    
    # –î–æ–±–∞–≤–ª—è–µ–º/–æ–±–Ω–æ–≤–ª—è–µ–º –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    for record in new_data:
        data_by_date[record["date"]] = record
    
    return list(data_by_date.values())


def sync_with_kolmo_history():
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç cbr_of_rub.json —Å –¥–∞—Ç–∞–º–∏ –∏–∑ kolmo_history.json.
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞—Ç—ã.
    """
    kolmo_dates = load_kolmo_history_dates()
    
    if not kolmo_dates:
        logger.error("–ù–µ—Ç –¥–∞—Ç –≤ kolmo_history.json –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏")
        return
    
    existing_data = load_existing_cbr_data()
    existing_dates = {record["date"] for record in existing_data}
    
    # –ù–∞—Ö–æ–¥–∏–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞—Ç—ã
    missing_dates = kolmo_dates - existing_dates
    
    if not missing_dates:
        logger.info("‚úÖ –í—Å–µ –¥–∞—Ç—ã –∏–∑ kolmo_history.json —É–∂–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ cbr_of_rub.json")
        return
    
    logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(missing_dates)} –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –¥–∞—Ç")
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
    missing_sorted = sorted(missing_dates)
    
    # –°–æ–∑–¥–∞—ë–º —Å–µ—Å—Å–∏—é —Å retry
    session = create_session_with_retries()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞—Ç—ã
    new_data = []
    failed_dates = []
    
    for i, date_str in enumerate(missing_sorted):
        target_date = datetime.strptime(date_str, "%Y-%m-%d").date()
        daily_data = fetch_cbr_daily(target_date, session)
        
        if daily_data:
            new_data.append(daily_data)
            logger.info(f"[{i+1}/{len(missing_sorted)}] –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {date_str}")
        else:
            failed_dates.append(target_date)
        
        if i < len(missing_sorted) - 1:
            time.sleep(0.2)
    
    # –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –¥–ª—è –Ω–µ—É–¥–∞—á–Ω—ã—Ö –¥–∞—Ç
    if failed_dates:
        logger.info(f"–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –¥–ª—è {len(failed_dates)} –¥–∞—Ç...")
        time.sleep(3)
        
        for failed_date in failed_dates[:]:
            daily_data = fetch_cbr_daily(failed_date, session)
            if daily_data:
                new_data.append(daily_data)
                failed_dates.remove(failed_date)
                logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–µ: {failed_date.strftime('%Y-%m-%d')}")
            time.sleep(0.5)
    
    if failed_dates:
        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {len(failed_dates)} –¥–∞—Ç: {[d.strftime('%Y-%m-%d') for d in failed_dates]}")
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
    merged_data = merge_cbr_data(existing_data, new_data)
    save_cbr_data(merged_data)
    
    logger.info(f"‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –î–æ–±–∞–≤–ª–µ–Ω–æ {len(new_data)} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π")


def update_to_today():
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç cbr_of_rub.json –¥–æ —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–π –¥–∞—Ç—ã.
    –ù–∞—á–∏–Ω–∞–µ—Ç —Å –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–∞—Ç—ã –≤ —Ñ–∞–π–ª–µ –∏–ª–∏ —Å –Ω–∞—á–∞–ª–∞ kolmo_history.
    """
    existing_data = load_existing_cbr_data()
    
    if existing_data:
        # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É
        last_date_str = max(record["date"] for record in existing_data)
        start_date = datetime.strptime(last_date_str, "%Y-%m-%d").date() + timedelta(days=1)
    else:
        # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, –ø—Ä–æ–±—É–µ–º –≤–∑—è—Ç—å –ø–µ—Ä–≤—É—é –¥–∞—Ç—É –∏–∑ kolmo_history
        kolmo_dates = load_kolmo_history_dates()
        if kolmo_dates:
            start_date = datetime.strptime(min(kolmo_dates), "%Y-%m-%d").date()
        else:
            start_date = date(2021, 7, 1)  # –î–µ—Ñ–æ–ª—Ç–Ω–∞—è –Ω–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞
    
    end_date = date.today()
    
    if start_date > end_date:
        logger.info("‚úÖ –î–∞–Ω–Ω—ã–µ —É–∂–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã –¥–æ —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–π –¥–∞—Ç—ã")
        return
    
    logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å {start_date} –ø–æ {end_date}")
    
    new_data = fetch_cbr_period(start_date, end_date)
    
    if new_data:
        merged_data = merge_cbr_data(existing_data, new_data)
        save_cbr_data(merged_data)
        logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(new_data)} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π")
    else:
        logger.warning("–ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è")


def fix_missing_dates():
    """
    –ù–∞—Ö–æ–¥–∏—Ç –∏ –∑–∞–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –¥–∞—Ç—ã –≤ cbr_of_rub.json.
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç—å –¥–∞—Ç –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ.
    """
    existing_data = load_existing_cbr_data()
    
    if not existing_data:
        logger.error("–§–∞–π–ª cbr_of_rub.json –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞—Ç—ã
    existing_dates = {record["date"] for record in existing_data}
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω
    min_date = datetime.strptime(min(existing_dates), "%Y-%m-%d").date()
    max_date = datetime.strptime(max(existing_dates), "%Y-%m-%d").date()
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Å–µ –¥–∞—Ç—ã –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
    all_dates = set()
    current = min_date
    while current <= max_date:
        all_dates.add(current.strftime("%Y-%m-%d"))
        current += timedelta(days=1)
    
    # –ù–∞—Ö–æ–¥–∏–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ
    missing_dates = all_dates - existing_dates
    
    if not missing_dates:
        logger.info("‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –¥–∞—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return
    
    logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(missing_dates)} –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –¥–∞—Ç")
    
    # –°–æ–∑–¥–∞—ë–º —Å–µ—Å—Å–∏—é —Å retry
    session = create_session_with_retries()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ
    missing_sorted = sorted(missing_dates)
    new_data = []
    still_missing = []
    
    for i, date_str in enumerate(missing_sorted):
        target_date = datetime.strptime(date_str, "%Y-%m-%d").date()
        daily_data = fetch_cbr_daily(target_date, session)
        
        if daily_data:
            new_data.append(daily_data)
            logger.info(f"[{i+1}/{len(missing_sorted)}] ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {date_str}")
        else:
            still_missing.append(date_str)
            logger.warning(f"[{i+1}/{len(missing_sorted)}] ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å: {date_str}")
        
        time.sleep(0.3)
    
    if new_data:
        merged_data = merge_cbr_data(existing_data, new_data)
        save_cbr_data(merged_data)
        logger.info(f"‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ {len(new_data)} –¥–∞—Ç")
    
    if still_missing:
        logger.warning(f"‚ö†Ô∏è –û—Å—Ç–∞–ª–∏—Å—å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏: {still_missing}")


def main():
    parser = argparse.ArgumentParser(
        description="–ó–∞–≥—Ä—É–∑–∫–∞ –∫—É—Ä—Å–æ–≤ –≤–∞–ª—é—Ç –¶–ë –†–§ –∏ —ç–∫—Å–ø–æ—Ä—Ç –≤ JSON"
    )
    
    parser.add_argument(
        "--start-date",
        type=str,
        help="–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD"
    )
    parser.add_argument(
        "--end-date",
        type=str,
        help="–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD"
    )
    parser.add_argument(
        "--sync",
        action="store_true",
        help="–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å –¥–∞—Ç–∞–º–∏ –∏–∑ kolmo_history.json"
    )
    parser.add_argument(
        "--update",
        action="store_true",
        help="–û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–æ —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–π –¥–∞—Ç—ã"
    )
    parser.add_argument(
        "--fix-missing",
        action="store_true",
        help="–ù–∞–π—Ç–∏ –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –¥–∞—Ç—ã"
    )
    
    args = parser.parse_args()
    
    print("\n" + "=" * 70)
    print("üìä CBR CURRENCY RATES EXPORTER")
    print("=" * 70)
    
    if args.sync:
        # –†–µ–∂–∏–º —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å kolmo_history.json
        sync_with_kolmo_history()
    
    elif args.fix_missing:
        # –†–µ–∂–∏–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –¥–∞—Ç
        fix_missing_dates()
        
    elif args.update:
        # –†–µ–∂–∏–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–æ —Å–µ–≥–æ–¥–Ω—è
        update_to_today()
        
    elif args.start_date and args.end_date:
        # –†—É—á–Ω–æ–π —Ä–µ–∂–∏–º —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –ø–µ—Ä–∏–æ–¥–∞
        start_date = datetime.strptime(args.start_date, "%Y-%m-%d").date()
        end_date = datetime.strptime(args.end_date, "%Y-%m-%d").date()
        
        existing_data = load_existing_cbr_data()
        new_data = fetch_cbr_period(start_date, end_date)
        
        if new_data:
            merged_data = merge_cbr_data(existing_data, new_data)
            save_cbr_data(merged_data)
        else:
            logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
    else:
        parser.print_help()
        print("\n‚ö†Ô∏è  –£–∫–∞–∂–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã: --sync, --update, --fix-missing –∏–ª–∏ --start-date/--end-date")
        return 1
    
    print("=" * 70 + "\n")
    return 0


if __name__ == "__main__":
    exit(main())
